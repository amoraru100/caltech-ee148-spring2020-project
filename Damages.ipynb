{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Reshape, Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input, concatenate\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_damages_cleaned_path = 'car_damages_cleaned.csv'\n",
    "data_dir = './data_damages/'\n",
    "\n",
    "damages_data = pd.read_csv(car_damages_cleaned_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df, column):\n",
    "    encoder_dict = {}\n",
    "    idx = 0\n",
    "    for i in range(len(df)) : \n",
    "        value = df.loc[i, column]\n",
    "        if (value not in encoder_dict):\n",
    "            encoder_dict[value] = idx\n",
    "            df.loc[i, column] = idx\n",
    "            idx += 1\n",
    "        else:\n",
    "            encoding = encoder_dict[value]\n",
    "            df.loc[i, column] = encoding\n",
    "    return df[column], encoder_dict\n",
    " \n",
    "modified_data = pd.DataFrame()\n",
    "modified_data['listing_id'] = damages_data['listing_id']\n",
    "modified_data['damage'], damage_encoder = encoder(damages_data, 'damage')\n",
    "modified_data['make'], make_encoder = encoder(damages_data, 'make')\n",
    "modified_data['model'], model_encoder = encoder(damages_data, 'model')\n",
    "modified_data['full_label'], full_label_encoder = encoder(damages_data, 'full_label')\n",
    "modified_data['est_value'] = damages_data['est_value']\n",
    "modified_data['year'] = damages_data['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>damage</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>full_label</th>\n",
       "      <th>est_value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23885009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12726</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24487306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25667019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13095</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25717579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4275</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25887480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7742</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id damage make model full_label  est_value  year\n",
       "0    23885009      0    0     0          0      12726  2010\n",
       "1    24487306      0    0     1          1       1984  2002\n",
       "2    25667019      0    0     2          2      13095  2012\n",
       "3    25717579      1    0     2          3       4275  2005\n",
       "4    25887480      0    0     3          4       7742  2008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique makes in dataset:  25\n",
      "Number of unique models in dataset:  498\n",
      "Number of unique damage types in dataset:  18\n",
      "Number of unique labels (make, model, and year) in dataset:  947\n",
      "Total number of datapoints:  1180\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique makes in dataset: ', len(modified_data.make.unique()))\n",
    "print('Number of unique models in dataset: ', len(modified_data.model.unique()))\n",
    "print('Number of unique damage types in dataset: ', len(modified_data.damage.unique()))\n",
    "print('Number of unique labels (make, model, and year) in dataset: ', len(modified_data.full_label.unique()))\n",
    "print('Total number of datapoints: ', len(modified_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images to Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images(df, column, idx):\n",
    "    for i in range(len(df)) : \n",
    "        listing_id = df.loc[i, 'listing_id']\n",
    "        image = Image.open(data_dir + '{}-{}.jpg'.format(listing_id, idx)).resize((250,250))\n",
    "        \n",
    "        image_array = np.array(image)\n",
    "        df.at[i, column] = image_array\n",
    "    return df[column]\n",
    "\n",
    "modified_data['image1'] = None\n",
    "modified_data['image2'] = None\n",
    "modified_data['image3'] = None\n",
    "modified_data['image1'] = convert_images(modified_data, 'image1', 1)\n",
    "modified_data['image2'] = convert_images(modified_data, 'image2', 2)\n",
    "modified_data['image3'] = convert_images(modified_data, 'image3', 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_data_path = 'modified_damages.csv'\n",
    "modified_data.to_csv(modified_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>damage</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>full_label</th>\n",
       "      <th>est_value</th>\n",
       "      <th>year</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>image3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23885009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12726</td>\n",
       "      <td>2010</td>\n",
       "      <td>[[[253, 255, 254], [253, 255, 254], [253, 255,...</td>\n",
       "      <td>[[[254, 254, 254], [254, 254, 254], [254, 254,...</td>\n",
       "      <td>[[[244, 246, 236], [244, 246, 237], [244, 245,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24487306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>2002</td>\n",
       "      <td>[[[134, 135, 127], [115, 116, 108], [126, 127,...</td>\n",
       "      <td>[[[74, 94, 118], [72, 93, 117], [73, 94, 119],...</td>\n",
       "      <td>[[[134, 146, 149], [135, 147, 150], [137, 150,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25667019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13095</td>\n",
       "      <td>2012</td>\n",
       "      <td>[[[72, 120, 169], [72, 120, 169], [72, 120, 16...</td>\n",
       "      <td>[[[78, 92, 94], [95, 109, 112], [91, 105, 108]...</td>\n",
       "      <td>[[[87, 132, 174], [87, 132, 174], [87, 132, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25717579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4275</td>\n",
       "      <td>2005</td>\n",
       "      <td>[[[58, 65, 75], [58, 65, 75], [53, 60, 70], [5...</td>\n",
       "      <td>[[[207, 224, 241], [223, 240, 252], [220, 237,...</td>\n",
       "      <td>[[[224, 225, 246], [224, 225, 246], [225, 226,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25887480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7742</td>\n",
       "      <td>2008</td>\n",
       "      <td>[[[108, 107, 102], [107, 106, 101], [109, 108,...</td>\n",
       "      <td>[[[183, 182, 187], [213, 212, 217], [197, 196,...</td>\n",
       "      <td>[[[220, 223, 228], [220, 223, 228], [220, 223,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id damage make model full_label  est_value  year  \\\n",
       "0    23885009      0    0     0          0      12726  2010   \n",
       "1    24487306      0    0     1          1       1984  2002   \n",
       "2    25667019      0    0     2          2      13095  2012   \n",
       "3    25717579      1    0     2          3       4275  2005   \n",
       "4    25887480      0    0     3          4       7742  2008   \n",
       "\n",
       "                                              image1  \\\n",
       "0  [[[253, 255, 254], [253, 255, 254], [253, 255,...   \n",
       "1  [[[134, 135, 127], [115, 116, 108], [126, 127,...   \n",
       "2  [[[72, 120, 169], [72, 120, 169], [72, 120, 16...   \n",
       "3  [[[58, 65, 75], [58, 65, 75], [53, 60, 70], [5...   \n",
       "4  [[[108, 107, 102], [107, 106, 101], [109, 108,...   \n",
       "\n",
       "                                              image2  \\\n",
       "0  [[[254, 254, 254], [254, 254, 254], [254, 254,...   \n",
       "1  [[[74, 94, 118], [72, 93, 117], [73, 94, 119],...   \n",
       "2  [[[78, 92, 94], [95, 109, 112], [91, 105, 108]...   \n",
       "3  [[[207, 224, 241], [223, 240, 252], [220, 237,...   \n",
       "4  [[[183, 182, 187], [213, 212, 217], [197, 196,...   \n",
       "\n",
       "                                              image3  \n",
       "0  [[[244, 246, 236], [244, 246, 237], [244, 245,...  \n",
       "1  [[[134, 146, 149], [135, 147, 150], [137, 150,...  \n",
       "2  [[[87, 132, 174], [87, 132, 174], [87, 132, 17...  \n",
       "3  [[[224, 225, 246], [224, 225, 246], [225, 226,...  \n",
       "4  [[[220, 223, 228], [220, 223, 228], [220, 223,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_consolidator(df):\n",
    "    images = np.zeros((250, 750, 3))\n",
    "    for i in range(len(df)):\n",
    "        image1 = df.loc[i, 'image1']\n",
    "        image2 = df.loc[i, 'image2']\n",
    "        image3 = df.loc[i, 'image3']\n",
    "        images[0:250, 0:250] = image1\n",
    "        images[0:250, 250:500] = image2\n",
    "        images[0:250, 500:750] = image3\n",
    "        df.at[i, 'images'] = images\n",
    "    return df['images']\n",
    "    \n",
    "modified_data['images'] = None\n",
    "modified_data['images'] = image_consolidator(modified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(modified_data[['listing_id', 'damage', 'make', 'model', 'year', 'full_label', 'images']], modified_data[['est_value']], test_size=0.20, random_state=2020)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(modified_data[['listing_id', 'damage', 'make', 'model', 'year', 'full_label', 'images']], modified_data[['est_value']], test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_images = x_train[['images']]/255\n",
    "x_valid_images = x_valid[['images']]/255\n",
    "x_test_images = x_test[['images']]/255\n",
    "\n",
    "x_train_attributes = x_train[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]\n",
    "x_valid_attributes = x_valid[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]\n",
    "x_test_attributes = x_test[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dimensions(df):\n",
    "    all_images = []\n",
    "    for i in range(len(df)):\n",
    "        idx = df.index[i]\n",
    "        all_images.append(df.loc[idx, 'images'])\n",
    "    return np.array(all_images)\n",
    "\n",
    "x_train_images = reshape_dimensions(x_train_images)\n",
    "x_valid_images = reshape_dimensions(x_valid_images)\n",
    "x_test_images = reshape_dimensions(x_test_images)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_data(regress=False):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    \n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "   \n",
    "    return model\n",
    "\n",
    "def image_data(regress=False):\n",
    "    \n",
    "    inputs = Input((250, 750, 3))\n",
    "    x = inputs\n",
    "    \n",
    "    x = Conv2D(16, (3,3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(10,10))(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    \n",
    "    x = Conv2D(64, (50,50), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(20,20))(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Dense(6)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    " \n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = categorical_data()\n",
    "cnn = image_data()\n",
    "\n",
    "final_input = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "x = Dense(6, activation=\"relu\")(final_input)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = Model([mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/3\n",
      "885/885 [==============================] - 817s 923ms/step - loss: 4561.2887\n",
      "Epoch 2/3\n",
      "885/885 [==============================] - 853s 964ms/step - loss: 99.9290\n",
      "Epoch 3/3\n",
      "885/885 [==============================] - 901s 1s/step - loss: 99.2095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x255d4e900b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model.fit([x_train_attributes, x_train_images], y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250, 750, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 250, 750, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 250, 750, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 250, 750, 16) 64          activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 75, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 25, 75, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, 75, 64)   2560064     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 75, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 3, 64)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 3, 64)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 192)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           3088        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16)           64          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_input (InputLayer)      (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            56          dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            102         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            36          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 6)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10)           0           dense_2[0][0]                    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            66          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            7           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,563,995\n",
      "Trainable params: 2,563,931\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting car prices...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting car prices...\")\n",
    "preds = model.predict([x_valid_attributes, x_valid_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_valid.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds)\n",
    "result = pd.concat([preds, y_valid['est_value']], axis=1, ignore_index = True)\n",
    "result.columns = ['Predicted', 'Actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An utter disappointment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>13195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>31168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>24038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>10751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>41205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>15317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>22403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>12039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>19211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1403.830078</td>\n",
       "      <td>11935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted  Actual\n",
       "0    1403.830078   13195\n",
       "1    1403.830078   31168\n",
       "2    1403.830078   24038\n",
       "3    1403.830078   10751\n",
       "4    1403.830078   41205\n",
       "..           ...     ...\n",
       "290  1403.830078   15317\n",
       "291  1403.830078   22403\n",
       "292  1403.830078   12039\n",
       "293  1403.830078   19211\n",
       "294  1403.830078   11935\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"An utter disappointment...\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150)\n",
    "print(\"Training model...\")\n",
    "clf.fit(x_train_attributes, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting car prices (without images)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting car prices (without images)...\")\n",
    "preds2 = clf.predict(x_valid_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = pd.DataFrame(preds2)\n",
    "result2 = pd.concat([preds2, y_valid['est_value']], axis=1, ignore_index = True)\n",
    "result2.columns = ['Predicted', 'Actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another utter disappointment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13892</td>\n",
       "      <td>13195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18243</td>\n",
       "      <td>31168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12601</td>\n",
       "      <td>24038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18047</td>\n",
       "      <td>10751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25508</td>\n",
       "      <td>41205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>12601</td>\n",
       "      <td>15317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>22830</td>\n",
       "      <td>22403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>4275</td>\n",
       "      <td>12039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>7717</td>\n",
       "      <td>19211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>8911</td>\n",
       "      <td>11935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Actual\n",
       "0        13892   13195\n",
       "1        18243   31168\n",
       "2        12601   24038\n",
       "3        18047   10751\n",
       "4        25508   41205\n",
       "..         ...     ...\n",
       "290      12601   15317\n",
       "291      22830   22403\n",
       "292       4275   12039\n",
       "293       7717   19211\n",
       "294       8911   11935\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Another utter disappointment...\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore (currently does not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(modified_data[['listing_id', 'damage', 'make', 'model', 'year', 'full_label', 'image1', 'image2', 'image3']], modified_data[['est_value']], test_size=0.20, random_state=2020)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(modified_data[['listing_id', 'damage', 'make', 'model', 'year', 'full_label', 'image1', 'image2', 'image3']], modified_data[['est_value']], test_size=0.25, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_images = x_train[['image1', 'image2', 'image3']]\n",
    "x_valid_images = x_valid[['image1', 'image2', 'image3']]\n",
    "x_test_images = x_test[['image1', 'image2', 'image3']]\n",
    "\n",
    "x_train_attributes = x_train[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]\n",
    "x_valid_attributes = x_valid[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]\n",
    "x_test_attributes = x_test[['listing_id', 'damage', 'make', 'model', 'year', 'full_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_data():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "def image_data():\n",
    "    image1 = Input((250, 250, 3))\n",
    "    image2 = Input((250, 250, 3))\n",
    "    image3 = Input((250, 250, 3))\n",
    "\n",
    "    conv1 = Conv2D(250, (3,3))(image1)\n",
    "    flat1 = Flatten()(conv1)\n",
    "    conv2 = Conv2D(250, (3,3))(image2)\n",
    "    flat2 = Flatten()(conv2)\n",
    "    conv3 = Conv2D(250, (3,3))(image3)\n",
    "    flat3 = Flatten()(conv3)\n",
    "\n",
    "    x = concatenate([image1, image2, image3])\n",
    "\n",
    "    x = Conv2D(16, (3,3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(6)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    model = Model([image1, image2, image3], x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer conv2d_39 was called with an input that isn't a symbolic tensor. Received type: <class 'NoneType'>. Full input: [None]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 697\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'NoneType'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-bfc97a93c8c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinal_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e9c3ecd42f3f>\u001b[0m in \u001b[0;36mimage_data\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer conv2d_39 was called with an input that isn't a symbolic tensor. Received type: <class 'NoneType'>. Full input: [None]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "mlp = categorical_data(6)\n",
    "cnn = image_data(250, 250, 3)\n",
    "\n",
    "final_input = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "x = Dense(6, activation=\"relu\")(final_input)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = Model([mlp.input, cnn.input], outputs=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
